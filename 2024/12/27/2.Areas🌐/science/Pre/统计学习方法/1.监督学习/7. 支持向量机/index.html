<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>7. 支持向量机 | yuezi</title><meta name="author" content="yuezi"><meta name="copyright" content="yuezi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="[TOC] 七、支持向量机 支持向量机（Support vector machines，SVM） 模型：定义特征空间上最大的线性分类器，区别于感知机模型，具备核技巧，所以也是非线性分类器 包括：线性可分支持向量机、线性支持向量机、非线性支持向量机   策略：间隔最大化，形式化为求解凸二次规划问题，等价正则化合页损失函数最小化问题 线性可分、线性支持、非线性支持向量机分别通过硬间隔最大化，软间隔最大">
<meta property="og:type" content="article">
<meta property="og:title" content="7. 支持向量机">
<meta property="og:url" content="https://yuezi2048.github.io/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/7.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/index.html">
<meta property="og:site_name" content="yuezi">
<meta property="og:description" content="[TOC] 七、支持向量机 支持向量机（Support vector machines，SVM） 模型：定义特征空间上最大的线性分类器，区别于感知机模型，具备核技巧，所以也是非线性分类器 包括：线性可分支持向量机、线性支持向量机、非线性支持向量机   策略：间隔最大化，形式化为求解凸二次规划问题，等价正则化合页损失函数最小化问题 线性可分、线性支持、非线性支持向量机分别通过硬间隔最大化，软间隔最大">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yuezi2048.github.io/img/touxiang.jpg">
<meta property="article:published_time" content="2024-12-27T03:07:14.000Z">
<meta property="article:modified_time" content="2024-12-27T03:07:14.000Z">
<meta property="article:author" content="yuezi">
<meta property="article:tag" content="1.监督学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yuezi2048.github.io/img/touxiang.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "7. 支持向量机",
  "url": "https://yuezi2048.github.io/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/7.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/",
  "image": "https://yuezi2048.github.io/img/touxiang.jpg",
  "datePublished": "2024-12-27T03:07:14.000Z",
  "dateModified": "2024-12-27T03:07:14.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "yuezi",
      "url": "https://yuezi2048.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://yuezi2048.github.io/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/7.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?bfb48b678d82bea9f9cc9d59227767e4";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"FPH6F2TOJL","apiKey":"06d9ea26c803ba912b4d8e13404ed34d","indexName":"blog","hitsPerPage":6,"languages":{"input_placeholder":"搜索","hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，耗时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":350,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '7. 支持向量机',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/backgound.css"><meta name="generator" content="Hexo 8.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/loading.gif" data-original="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">785</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">66</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">91</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/default.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">yuezi</span></a><a class="nav-page-title" href="/"><span class="site-name">7. 支持向量机</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">7. 支持向量机</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-12-27T03:07:14.000Z" title="发表于 2024-12-27 11:07:14">2024-12-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-12-27T03:07:14.000Z" title="更新于 2024-12-27 11:07:14">2024-12-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/">2.Areas🌐</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/science/">science</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/science/Pre/">Pre</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/">统计学习方法</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">1.监督学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">5.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>[TOC]</p>
<h1 id="七、支持向量机"><a href="#七、支持向量机" class="headerlink" title="七、支持向量机"></a>七、支持向量机</h1><ul>
<li><code>支持向量机</code>（Support vector machines，SVM）<ul>
<li>模型：定义特征空间上最大的线性分类器，区别于感知机模型，具备<code>核技巧</code>，所以也是非线性分类器<ul>
<li>包括：<strong>线性可分支持向量机、线性支持向量机、非线性支持向量机</strong></li>
</ul>
</li>
<li>策略：间隔最大化，形式化为求解<code>凸二次规划</code>问题，等价<code>正则化合页损失函数最小化</code>问题<ul>
<li>线性可分、线性支持、非线性支持向量机分别通过<strong>硬间隔最大化，软间隔最大化，核技巧及软间隔最大化</strong>来学习</li>
</ul>
</li>
<li>算法：求解凸二次规划最优化算法</li>
</ul>
</li>
<li><code>核函数</code>：将输入从 输入空间映射 到特征空间得到的特征向量之间的<code>内积</code>，进而帮助我们学习非线性支持向量机，隐式地从高维特征中学习线性支持向量机。</li>
</ul>
<h2 id="7-1-线性可分支持向量机"><a href="#7-1-线性可分支持向量机" class="headerlink" title="7.1 线性可分支持向量机"></a>7.1 线性可分支持向量机</h2><h3 id="7-1-1-线性可分SVM模型"><a href="#7-1-1-线性可分SVM模型" class="headerlink" title="7.1.1 线性可分SVM模型"></a>7.1.1 线性可分SVM模型</h3><p>给出训练数据集：</p>
<ul>
<li>符号说明：$x_i$表示第i个特征向量实例，$y_i$是类标记，取值为+1和-1，表示正例和负例。</li>
<li>对于该模型，我们假设训练数据集<code>线性可分</code>（见定义2.2）</li>
<li>训练目标：在特征空间中找到<strong>分离超平面</strong>，让实例分到不同的类，并通过间隔最大化求得最优分离超平面（区别于感知机，此时超平面是唯一的）</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106161954098.png" alt="image-20241106161954098">	</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106162347708.png" alt="image-20241106162347708" style="zoom:80%;" />	

<p>二类分类问题的示意图如下，下一小节，我们介绍如何度量点到平面的间隔，进而为后续的间隔最大化策略做铺垫。</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106162545443.png" alt="image-20241106162545443">	</p>
<h3 id="7-1-2-函数间隔与几何间隔"><a href="#7-1-2-函数间隔与几何间隔" class="headerlink" title="7.1.2 函数间隔与几何间隔"></a>7.1.2 函数间隔与几何间隔</h3><ul>
<li><strong>通过点距离平面超平面的远近来表示分类预测的确信程度</strong><ul>
<li>如上图所示，对于距分离超平面较远的A点，我们预测该点为正类则更加确信，对于较近的C点，则认为该点预测为正类则不那么确信</li>
</ul>
</li>
<li><code>函数间隔</code>：对于$w · x + b &#x3D; 0$超平面，$|w · x + b|$则表示点x距离超平面的远近，通过其符号与类标记y是否一致来表示分类是否正确<ul>
<li>考虑到平面系数变为原来的k倍后，超平面不变，函数间隔变为k倍，因此我们可以加入规范化约束$|w|&#x3D;1$使得函数间隔固定</li>
</ul>
</li>
</ul>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106163258238.png" alt="image-20241106163258238" style="zoom:80%;" />	

<ul>
<li><code>几何间隔</code>：相对函数间隔，几何间隔则对应几何意义上真实的距离，距离为$\gamma_i&#x3D;y_i\left(\frac{w}{|w|}\bullet x_i+\frac{b}{|w|}\right)$<ul>
<li>从图7.2中看到，点A（正例）到超平面的几何间隔为$\gamma_i&#x3D;\frac w{|w|}\bullet x_i+\frac b{|w|}$</li>
<li>那么负例点到超平面的几何间隔为$\gamma_i&#x3D;-\left(\frac{w}{|w|}\bullet x_i+\frac{b}{|w|}\right)$</li>
</ul>
</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106165330625.png" alt="image-20241106165330625">	</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106170120536.png" alt="image-20241106170120536" style="zoom:80%;" />	

<blockquote>
<p>注：几何间隔是实例点到超平面的<strong>带符号距离</strong>，当样本点被正确分类时，才是实例点到超平面距离，后面说到软间隔的部分会提到误分类点的问题</p>
</blockquote>
<ul>
<li>函数间隔和几何间隔的关系，一句话来说就是：几何间隔就是函数间隔基础上除以$|w|$（下标加i表示样本点）<ul>
<li>特别地，当$|w|&#x3D;1$时，函数间隔和几何间隔相等，此时等比例改变w和 b，函数间隔成比例改变，几何间隔不变。</li>
</ul>
</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106170610055.png" alt="image-20241106170610055">	</p>
<h3 id="7-1-3-硬间隔最大化策略"><a href="#7-1-3-硬间隔最大化策略" class="headerlink" title="7.1.3 硬间隔最大化策略"></a>7.1.3 硬间隔最大化策略</h3><ul>
<li><code>硬间隔最大化</code>：支持向量机的思路就是求解正确划分数据集并且<strong>几何间隔最大</strong>的分离超平面，对线性可分的训练数据集而言，是唯一的（区别于感知机是无穷多个）</li>
<li>怎么找这唯一的超平面：几何间隔最大意味着确信度最大地对数据进行分类，那么思路就是：将 离超平面最近的点（支持向量）需要有足够大的确信度分开。</li>
</ul>
<h4 id="最大间隔分离超平面学习"><a href="#最大间隔分离超平面学习" class="headerlink" title="最大间隔分离超平面学习"></a>最大间隔分离超平面学习</h4><ul>
<li>约束条件就是找到几何间隔最小的向量$\gamma$，即离超平面最近的点，</li>
<li>目标函数就是表明该向量要有最大的几何间隔，即求得足够大的确信度</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106171610017.png" alt="image-20241106171610017">	</p>
<p>上述公式可以改写为函数间隔的形式，此时具有如下特性：</p>
<ul>
<li>考虑函数间隔的性质，函数间隔$\hat{\gamma}$ 不会影响最优化问题的最终的解</li>
<li>所以可以简化问题 $\hat{\gamma}&#x3D;1$ 来代入问题</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106171904743.png" alt="image-20241106171904743">	</p>
<ul>
<li>又考虑到最大化 $\frac{1}{|w|}$和最小化 $\frac{1}{2}|w|^2$等价的，进一步简化我们的策略函数</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106173826635.png" alt="image-20241106173826635">	</p>
<ul>
<li>这是一个<code>凸优化问题</code>，即关于如下的约束优化问题<ul>
<li>其中$f(w)$和约束函数$g_i(w)$都是$R^n$上的连续可微凸函数，约束函数$h_i(w)$是<code>仿射函数</code>（即函数$f(x)$满足$f(x)&#x3D;a\bullet x+b$，矩阵线性变换+平移）</li>
</ul>
</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106172835201.png" alt="image-20241106172835201">	</p>
<p>此时，如果又满足目标函数$f(w)$为二次函数，且约束函数$g_i(w)$也是仿射函数时，我们可以将上述凸最优化问题转变为<code>凸二次规划问题</code></p>
<p>通过二次规划求解后，得到解$w^{<em>},b^{</em>}$，进而得到分离超平面$w^{<em>}\bullet x+b^{</em>}&#x3D;0$和分类决策函数$f(x)&#x3D;\mathrm{sign}(w^<em>\bullet x+b^</em>)$ ，即得到最终的线性可分SVM模型。</p>
<h4 id="【算法7-1】-最大间隔法描述"><a href="#【算法7-1】-最大间隔法描述" class="headerlink" title="【算法7.1】 最大间隔法描述"></a>【算法7.1】 最大间隔法描述</h4><p>做了上述的分析后，得到最大间隔法的学习策略如下：</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106173503622.png" alt="image-20241106173503622">	</p>
<h4 id="最大间隔分离超平面存在唯一性证明"><a href="#最大间隔分离超平面存在唯一性证明" class="headerlink" title="最大间隔分离超平面存在唯一性证明"></a>最大间隔分离超平面存在唯一性证明</h4><p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106173626224.png" alt="image-20241106173626224">	</p>
<ul>
<li><strong>存在性证明</strong><ul>
<li>因为线性可分，所以最优化问题（7.13-7.14）存在可行解（注：在低维如果不可分，那么在高维应线性可分）</li>
<li>又因为目标函数有下界，那么必定有解 $(w^{<em>},b^{</em>})$</li>
<li>又由于数据集既有正类又有负类，那么不可能有$(w^{<em>},b^{</em>})&#x3D;(0,b)$最优化可行解</li>
<li>综上，最优解$(w^{<em>},b^{</em>})$且$w \neq 0$ 就证明存在性</li>
</ul>
</li>
<li><strong>唯一性证明</strong><ul>
<li>李航老师主要是通过反证法证明的：即我假设如果存在两个最优化解，只要说明这两个点的w和b相同即可</li>
<li>证明w变量时，大概思路是引入中间值（非最优解），然后通过向量三角不等式说明上界，得到两个向量在同一个方向上并且长度相同</li>
<li>在证明b变量时，这里是引入两个平面对应4个可能的支持向量的关系，使用两个条件：<ul>
<li>a. 支持向量的点距离平面的距离（<code>几何间隔</code>）为1； —&gt; 得到b1 b2关于w*和x的表达式</li>
<li>b. 其余的点距离平面的距离不低于1  —&gt;  得到 x1’’ &#x3D; x2’’，x1’ &#x3D; x2’</li>
</ul>
</li>
</ul>
</li>
</ul>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106174510292.png" alt="image-20241106174510292" style="zoom: 80%;" />	

<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241106174539683.png" alt="image-20241106174539683" style="zoom:80%;" />	

<h4 id="支持向量和间隔边界"><a href="#支持向量和间隔边界" class="headerlink" title="支持向量和间隔边界"></a>支持向量和间隔边界</h4><p>在上面的存在唯一性证明过程当中，提到了支持向量和间隔边界相关的概念，我们具体来说明。</p>
<ul>
<li><code>支持向量</code>：分离超平面最近的样本点实例，即使得式7.14等号成立的点</li>
<li><code>间隔边界</code>：H1和H2为<code>间隔边界</code><ul>
<li><code>间隔</code>：H1和H2的距离为间隔（margin） 间隔的值依赖于分离超平面法向量w，为$\frac{2}{w}$</li>
</ul>
</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241109222351350.png" alt="image-20241109222351350">	</p>
<p>给出了一个案例，实际上就是将每个点代入到原策略函数中，然后求解二次规划问题。</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241109222644061.png" alt="image-20241109222644061">	</p>
<h3 id="7-1-4-对偶算法"><a href="#7-1-4-对偶算法" class="headerlink" title="7.1.4 对偶算法"></a>7.1.4 对偶算法</h3><p><strong>为什么要进行对偶求解</strong></p>
<ul>
<li>更容易求解（对偶问题一定是凸函数，即局部最优满足全局最优）</li>
<li>便于后续引入<code>核函数</code></li>
</ul>
<h4 id="对偶求解过程"><a href="#对偶求解过程" class="headerlink" title="对偶求解过程"></a>对偶求解过程</h4><ul>
<li><p>首先构造拉格朗日函数，$α_i$为拉格朗日因子，且满足$α_i\geq0$</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110201524584.png" alt="image-20241110201524584">        </p>
</li>
<li><p>通过拉格朗日对偶性，原始问题的对偶问题就转变为<code>极大极小问题</code>（注：这里的α是由$(\alpha_1. \alpha_2…,α_n)^{T}$构成的拉格朗日向量）</p>
<ul>
<li>（为什么要取极大值？本章最后一小节说明，大概先看看整个过程怎么样的）</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110201737308.png" alt="image-20241110201737308">    </p>
<ul>
<li><p>首先求解L函数关于w,b 的极小值，通过偏导&#x3D;0计算得到7.19和7.20约束式</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110202322035.png" alt="image-20241110202322035">        </p>
</li>
<li><p>将7.19的w表达式代入原来的拉格朗日7.18式后，进一步得到外层最小化问题，而如果转化为最大最小问题，那么就是对偶问题了（先不急着回答为什么能转换成对偶问题，最后一小节会提到）</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110202433452.png" alt="image-20241110202433452"></p>
</li>
</ul>
</li>
<li><p>考虑凸函数的标准形式，对偶问题可以等价为如下形式，可通过二次规划求出来解α*</p>
</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110202531459.png" alt="image-20241110202531459">	</p>
<ul>
<li>得到α、*后，可通过定理7.2得到w*和b*的表达式，进而得到最后的超平面</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110202937627.png" alt="image-20241110202937627">	</p>
<p>定理证明过程如下：</p>
<ul>
<li>w*是基于KKT条件直接得到（KKT是什么？为什么能用KKT条件？和对偶到底有什么关系？）<ul>
<li>其中KKT第三个式子来由：对于间隔边界的点，右边项为0，而对于其他点α&#x3D;0，综上，相乘为0</li>
</ul>
</li>
<li>通过至少存在$α_j^{<em>}&gt;0$，即支持向量，得到KKT第四个取相等的条件，于是就可以得到b</em>的表达式</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110203127260.png" alt="image-20241110203127260">	</p>
<p>最后通过定理求得参数w* b*后，就可以得到最终的超平面和决策函数</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110203157034.png" alt="image-20241110203157034">	</p>
<h4 id="【算法7-2】-线性可分SVM对偶算法描述"><a href="#【算法7-2】-线性可分SVM对偶算法描述" class="headerlink" title="【算法7.2】 线性可分SVM对偶算法描述"></a>【算法7.2】 线性可分SVM对偶算法描述</h4><ul>
<li><p>最优化问题由7.22-7.24得到，即我们构造的拉格朗日函数求极值后的等式条件</p>
</li>
<li><p>计算由式7.25-7.26得到，主要是通过对偶问题的KKT条件，可以发现w*和b*参数的求解只依赖于$\alpha_i^{*}&gt;0$的样本点（<code>支持向量</code>）</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110210315041.png" alt="image-20241110210315041">    </p>
<ul>
<li>求解α*可通过SMO算法进行求解</li>
</ul>
</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110203545251.png" alt="image-20241110203545251">	</p>
<p>给出该算法具体的例子便于快速理解回顾</p>
<ul>
<li>注意一点，这里的极值点如果不满足约束条件，极值应当取边界值</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110210412401.png" alt="image-20241110210412401">	</p>
<h4 id="凸优化补充：KKT-Slater-对偶-流程总结"><a href="#凸优化补充：KKT-Slater-对偶-流程总结" class="headerlink" title="*凸优化补充：KKT Slater 对偶 + 流程总结"></a>*凸优化补充：KKT Slater 对偶 + 流程总结</h4><p>凸优化最优解问题格式：</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110203758672.png" alt="image-20241110203758672">	</p>
<p>什么是凸函数<br>1、目的是求取目标函数的最小值；<br>2、目标函数和不等式约束函数都是凸函数，定义域是凸集；<br>3、若存在等式约束函数，则等式约束函数为仿射函数；<br>4、对于凸优化问题具有良好的性质，局部最优解便是全局最优解。</p>
<p><strong>对偶问题,slater条件,KKT条件</strong></p>
<p>对于凸函数求解，我们一般是采用拉格朗日乘子法构建函数（其中α≥0、β任意，均为拉格朗日乘子，i&#x3D;1,2,…,p且j&#x3D;1,2,…,q）</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110203942846.png" alt="image-20241110203942846">	</p>
<p>但是考虑到如果要直接全部求偏导，光参数α和β就有p+q个了，所以考虑使用对偶问题简化计算</p>
<p>考虑这样一个函数，思考：为什么要求最大值？？</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110204356998.png" alt="image-20241110204356998" style="zoom:67%;" />	

<p>不难得到这样的关系</p>
<ul>
<li><p>（1）式表示，当约束条件满足时，拉格朗日函数最大值就是f(x)</p>
</li>
<li><p>（2）表明，约束条件只要有一个不满足，结果就是无穷大</p>
</li>
</ul>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110204410568.png" alt="image-20241110204410568" style="zoom:67%;" />	

<p>那么我们可以解答刚刚提出的问题，求最大值后，就可以对原问题的约束条件进行吸收，进而可以表示成能够进行对偶的形式</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110204641969.png" alt="image-20241110204641969">	</p>
<p>进而转变为对偶问题</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110204719905.png" alt="image-20241110204719905" style="zoom:67%;" />	

<p>看下面这种图，给定原问题和对偶问题的结果P和Q，一般来说P ≤ Q（矮个子里的高个子比不过凤凰的尾巴），没取到等号那就是弱对偶，此时对偶问题不能等价转换<br>但是如果我满足了<code>Slater条件和KKT条件</code>，就可以取到这个等号，那么就是强对偶，我就可以转换为对偶问题</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110204804238.png" alt="image-20241110204804238">	</p>
<p><code>slater条件</code>定义：存在x，使得不等式约束g(x)&lt;&#x3D;0严格成立，即保证了鞍点的存在。<br><code>KKT条件</code>如下：</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110205127178.png" alt="image-20241110205127178" style="zoom:67%;" />	

<ul>
<li>第一个条件表示满足约束条件</li>
<li>第二个条件表示最优点x, f必须是gi和hj的线性組合</li>
<li>第三个条件是限制拉格朗日的条件，对每一个α都必须大于或等于零，而对于等式，β不等于0</li>
</ul>
<p>这张图对上述过程总结的很到位。</p>
<p><img src="/img/loading.gif" data-original="https://pic1.zhimg.com/v2-3dac84c2edd9f279ac72a5679e5b0268_1440w.png" alt="img">	</p>
<p>参考资料：</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28804123">第四话：拉格朗日对偶问题</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/58064316">凸优化（slater条件探讨）</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/43874179">支持向量机（SVM）必备知识(KKT、slater、对偶）</a></p>
<h2 id="7-2-线性支持支持向量机"><a href="#7-2-线性支持支持向量机" class="headerlink" title="7.2 线性支持支持向量机"></a>7.2 线性支持支持向量机</h2><h3 id="7-2-1-线性支持SVM模型"><a href="#7-2-1-线性支持SVM模型" class="headerlink" title="7.2.1 线性支持SVM模型"></a>7.2.1 线性支持SVM模型</h3><ul>
<li>问题：线性可分终究是理想情况，实际是会有<code>特异点（outlier）</code>，即在采取硬间隔最大化时 7.14约束条件并不是所有点都成立的</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110211256991.png" alt="image-20241110211256991">	</p>
<ul>
<li>解决方案：模型策略从<code>硬间隔最大化</code>优化为<code>软间隔最大化</code>，接下来详细说明软间隔是什么。</li>
</ul>
<p>引入松弛变量$\xi_{i}\geqslant0$，并对于每个松弛变量都需支付代价$\xi_i$，目标函数和约束条件修改为如下：</p>
<ul>
<li><p>对约束条件的理解：</p>
<ul>
<li>对于正确分类点，$\xi_i&#x3D;0$，那么和前面的一样</li>
<li>对于误分类点，$\xi_i&gt;0$，那么就允许约束条件大于更小的距离（包括负数）</li>
</ul>
</li>
<li><p>对于目标函数的理解</p>
<ul>
<li>C &gt; 0 是惩罚参数，用于<strong>协调函数间隔和误分类点个数</strong></li>
</ul>
</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110211452633.png" alt="image-20241110211452633">	</p>
<p>那么采用软间隔得到的问题如下</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110211557131.png" alt="image-20241110211557131">	</p>
<p>类似地，求解后的分类决策函数模型就是<code>线性支持向量机</code></p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110211703845.png" alt="image-20241110211703845">	</p>
<h3 id="7-2-2-对偶算法"><a href="#7-2-2-对偶算法" class="headerlink" title="7.2.2 对偶算法"></a>7.2.2 对偶算法</h3><p>有了上一节的铺垫，我们按照同样的方式进行对偶算法的分析，无非多了一个松弛变量进行约束。</p>
<ul>
<li>式7.49得到关于$\alpha_i$不等式的具体解释说明</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110212431276.png" alt="image-20241110212431276">	</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110212159479.png" alt="image-20241110212159479">	</p>
<p>一样地，求得α后，通过对偶问题KKT条件可以得到对应的w b的解，进而代入得到最终的模型</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110212634408.png" alt="image-20241110212634408"></p>
<p>解释一下，为什么存在$0&lt;α_j^{*}&lt;C$（支持向量），就有等号成立，以及b的表达式7.51具体是怎么推导的。</p>
<ul>
<li>等号成立看7.53，首先说明$\xi_i^{*}&#x3D;0$，然后左边式子不等于0就可以推得</li>
<li>b的表达式就是把这个结论代入w的表达式就可以得到，其中有一个隐含条件是yj的平方是1</li>
</ul>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110213318867.png" alt="image-20241110213318867" style="zoom:67%;" />	

<h4 id="【算法7-3】-线性支持SVM算法描述"><a href="#【算法7-3】-线性支持SVM算法描述" class="headerlink" title="【算法7.3】 线性支持SVM算法描述"></a>【算法7.3】 线性支持SVM算法描述</h4><p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110212729995.png" alt="image-20241110212729995">	</p>
<h3 id="7-2-3-支持向量"><a href="#7-2-3-支持向量" class="headerlink" title="7.2.3 支持向量"></a>7.2.3 支持向量</h3><p>那么对偶问题的支持向量是满足什么条件呢？通过这个图来看</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110213758701.png" alt="image-20241110213758701">	</p>
<p>对应的关系说明：</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110214139267.png" alt="image-20241110214139267">	</p>
<p><font color="red">为什么？</font></p>
<p>根据这些约束条件：</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110214312963.png" alt="image-20241110214312963">	</p>
<p>而几何间隔d计算公式为：</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110214516392.png" alt="image-20241110214516392">	</p>
<p>以第一种情况为例子：如果$\alpha_i^{<em>}&lt;C$，那么由式7.43得到，u*&gt;0，那么就可以推得$\xi_i^{</em>}&#x3D;0$，进而由式7.53得到几何间隔为1，所以在间隔边界上。</p>
<p>其他同理（第二种情况对应0&lt;d&lt;1，第三种情况对应d&#x3D;0，第四种情况对应d&lt;0）</p>
<h3 id="7-2-4-合页损失函数"><a href="#7-2-4-合页损失函数" class="headerlink" title="7.2.4 合页损失函数"></a>7.2.4 合页损失函数</h3><p>对于线性支持向量机的学习，有另外一种等价形式：</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110215110150.png" alt="image-20241110215110150">	</p>
<ul>
<li><p>这里第一项是经验损失，而下面这个函数就是<code>合页损失函数</code>，第二项则是一个L2范数的正则化项</p>
<p>  <img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110215140787.png" alt="image-20241110215140787">    </p>
</li>
<li><p>右下角的+号表示取正值函数</p>
<p>  <img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110215236669.png" alt="image-20241110215236669"></p>
</li>
</ul>
<p>理解：之所以是等价描述，关键是第一项，当样本点被正确分类且函数间隔y(wx + b) &gt; 1时，损失为0，否则损失为 1-y(wx+b)</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110215559719.png" alt="image-20241110215559719">	</p>
<p>证明：</p>
<ul>
<li>实际上隐含了7.61和7.62两个隐藏条件</li>
<li>小于等于0时得到的结果是因为不等式$1-y_i(w\bullet x_i+b)\leqslant0\leqslant\xi_i$</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110215807828.png" alt="image-20241110215807828">	</p>
<p>结合上述的函数，给出0-1损失函数 感知机和合页损失函数的图像对比</p>
<ul>
<li><p>线性支持SVM的损失函数在0-1损失函数的基础是连续可导的，可作为0-1函数优化的上界（合页损失函数）目标函数</p>
</li>
<li><p>因为SVM的确信度问题造成了偏移，因为SVM要求距离（确信度）大于等于1，而感知机只要求距离&gt;&#x3D;0</p>
</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241110220124862.png" alt="image-20241110220124862">	</p>
<h2 id="7-3-非线性支持向量机与核函数"><a href="#7-3-非线性支持向量机与核函数" class="headerlink" title="7.3 非线性支持向量机与核函数"></a>7.3 非线性支持向量机与核函数</h2><h3 id="7-3-1-核技巧"><a href="#7-3-1-核技巧" class="headerlink" title="7.3.1 核技巧"></a>7.3.1 核技巧</h3><h4 id="非线性分类问题"><a href="#非线性分类问题" class="headerlink" title="非线性分类问题"></a>非线性分类问题</h4><p>这里给出了一个感性的理解图</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111195804491.png" alt="image-20241111195804491">	</p>
<p>李航老师关于<code>核函数</code>理论的解释见下面这张图</p>
<ul>
<li>结合上面的图说明，什么是核技巧呢？<ul>
<li>实际上就是在二维平面中的$x_1^2+x_2^2&#x3D;0(w&#x3D;1, b&#x3D;0)$（此时线性不可分），在三维平面就可以看成$z_1+z_2&#x3D;0$（此时线性可分）</li>
<li>然后我们的模型在这个三维平面上跑，学习得到最终的分类模型</li>
</ul>
</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111201130515.png" alt="image-20241111201130515">	</p>
<h4 id="核函数定义"><a href="#核函数定义" class="headerlink" title="核函数定义"></a>核函数定义</h4><p>在说明核函数之前，涉及到一些概念进行补充理解</p>
<ul>
<li>什么是<code>希尔伯特空间</code>？<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/88946250">是一个完备的内积空间</a></li>
</ul>
</li>
<li>什么是<code>内积</code>？<code>内积空间</code>是什么？<code>完备</code>又怎么理解？<ul>
<li>内积：对于一个线性空间中的任意三个矢量 φ,ψ,χ 和一个复数域上的数 a ，满足以下交换律结合律以及自乘率</li>
<li>内积空间：定义内积的线性空间</li>
<li>空间完备性：对于一个内积空间, 其任一<code>柯希序列</code>的极限也属于这个空间时，则这个性质叫空间的完备性。<ul>
<li>柯西（Cauchy）序列：简单理解，去掉有限个点后，剩下的最大向量长度小于任意正整数</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111202241806.png">	</p>
<p>李航老师给出的定义见下图</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111201853115.png" alt="image-20241111201853115" style="zoom:80%;" />	

<p>这里放一下关于映射关系的例子（映射关系不是唯一的，只是演示不同维度的映射），并给出一些相关点</p>
<ul>
<li>这边核函数作用是降维吗？更深一步说，本质应该还是为了简化运算。</li>
</ul>
<blockquote>
<p>注：我们实际上只需直接计算核函数K(x, z) （简单），不需要把两个映射关系求出来（复杂）</p>
</blockquote>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111202930166.png" alt="image-20241111202930166" style="zoom:67%;" />	

<h4 id="核函数在SVM的应用"><a href="#核函数在SVM的应用" class="headerlink" title="核函数在SVM的应用"></a>核函数在SVM的应用</h4><p>我们之前7.37式子中的原有对偶问题，使用核函数代替，就可以通过核技巧来求解非线性问题了</p>
<ul>
<li>接下来的问题是核函数如何选择？我们下一小节会再深入说明。</li>
</ul>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111203246761.png" alt="image-20241111203246761">	</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111203304095.png" alt="image-20241111203304095" style="zoom:67%;" />	

<h3 id="7-3-2-正定核"><a href="#7-3-2-正定核" class="headerlink" title="7.3.2 正定核"></a>7.3.2 正定核</h3><p>前面提到，构造映射函数是一件复杂的事情，而我们一般是通过直接求核函数K(x, z)。那么可不可以直接通过一个给定的函数是不是核函数？</p>
<p>首先给出<code>正定核</code>的概念，核函数实际上也叫正定核函数（positive definite kernel function）。</p>
<p>假设：$K(x,z)\text{ 是定义在 }\mathcal{X}\times\mathcal{X}\text{ 上的对称函数}\text{并且对任意的 }x_1,x_2,\cdots,x_m\in\mathcal{X}\text{,}K(x,z)\text{ 关于 }x_1,x_2,\cdots,x_m\text{ 的 Gram 矩阵是半正定的。}$</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/105470826">Gram矩阵半正定证明</a></p>
<p>（等价的命题：对于任意 n 阶实对称半正定矩阵 M, 存在矩阵 A 使得 M&#x3D;ATA 成立，核心思路是通过正交对角化的性质，然后对特征矩阵求根转换得到ATA的形式）</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111204630407.png" alt="image-20241111204630407" style="zoom: 67%;" />	

<h4 id="定义映射"><a href="#定义映射" class="headerlink" title="定义映射"></a>定义映射</h4><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111205207953.png" alt="image-20241111205207953" style="zoom:80%;" />	

<blockquote>
<p>注：这里线性组合是元素的集合S（因为αi取值），因为加法惩罚封闭的，所以可以定义向量空间。</p>
</blockquote>
<h4 id="定义内积空间S"><a href="#定义内积空间S" class="headerlink" title="定义内积空间S"></a>定义内积空间S</h4><ul>
<li>前面说过，核函数是两个映射函数的乘积，那么类似地定义另外一个线性组合，然后接下来要证明是否满足内积条件</li>
</ul>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111205401036.png" alt="image-20241111205401036" style="zoom:67%;" />	

<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111205410446.png" alt="image-20241111205410446" style="zoom:67%;" />	

<p>7.74-7.76式，通过7.70-7.72得到和K(x, z)对称性得到（乘法交换律）</p>
<ul>
<li>7.75式子前面一项，整合一个1~(m+l)的求和和后面的式子等价</li>
</ul>
<p>对于式7.77，由于半正定，所以可以得到大于等于0</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111210022931.png" alt="image-20241111210022931">	</p>
<p>对于7.78，右边可以得到左边，主要说明左边推右边，即必要性。</p>
<p>这里给出一个不等式（证明思路是通过f + λg的线性组合代入7.77式后，看成关于λ未知函数，使用判别式得到）</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111210135144.png" alt="image-20241111210135144">	</p>
<p>然后代入7.77式，得到一个式子</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111210433371.png" alt="image-20241111210433371">	</p>
<p>这里通过7.73的运算定义</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111210457898.png" alt="image-20241111210457898" style="zoom:67%;" />	

<p>将左边的式子替换后就是得到的结果</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111210526976.png" alt="image-20241111210526976" style="zoom:67%;" />	

<p>至此，上述运算*就是内积运算，可以表示为：</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111210623885.png" alt="image-20241111210623885" style="zoom:80%;" />	

<h4 id="内积空间完备化为希尔伯特空间"><a href="#内积空间完备化为希尔伯特空间" class="headerlink" title="内积空间完备化为希尔伯特空间"></a>内积空间完备化为希尔伯特空间</h4><p>通过内积得到范数</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111210729956.png" alt="image-20241111210729956" style="zoom:67%;" />	

<ul>
<li>得到范数后，得到S是<code>赋范向量空间</code>，根据泛函分析理论，我们一定可以使得完备化，根据前面的希尔伯特空间定义，一旦完备就能得到希尔伯特空间H</li>
<li>我们将该希尔伯特空间成为<code>再生核希尔伯特空间</code>（reproducing kernel Hilbert space RKHS），即满足再生核性质的希尔伯特空间：</li>
</ul>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111210914231.png" alt="image-20241111210914231" style="zoom:67%;" />	

<h4 id="结论：正定核充要条件"><a href="#结论：正定核充要条件" class="headerlink" title="结论：正定核充要条件"></a>结论：正定核充要条件</h4><p>实际上前面都是为了我们这个主题进行铺垫：到底什么函数满足正定核条件？</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111211043526.png" alt="image-20241111211043526" style="zoom:80%;" />	

<ul>
<li>必要性证明思路：核函数转换成内积后，结合Gram对称性质，化简为一个平方相乘的格式，得到K是半正定矩阵结论</li>
<li>充分性证明思路：前面的铺垫实际上都是为了证明充分性，根据Gram矩阵半正定的假设，可以得到希尔伯特映射，通过7.83的性质可以得到核函数可以通过映射函数相乘</li>
</ul>
<p>给出等价定义</p>
<ul>
<li>对称函数在构造核函数的时候会比较友好</li>
</ul>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111211629049.png" alt="image-20241111211629049" style="zoom:80%;" />	

<blockquote>
<p>实际上，在有限输入及判断Gram是否半正定也不容易。。我们往往直接拿已有的核函数</p>
</blockquote>
<h3 id="7-3-3-常用核函数"><a href="#7-3-3-常用核函数" class="headerlink" title="7.3.3 常用核函数"></a>7.3.3 常用核函数</h3><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111211852031.png" alt="image-20241111211852031" style="zoom:80%;" />	

<p><strong>字符串核函数</strong></p>
<p>映射定义</p>
<img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111212021898.png" alt="image-20241111212021898" style="zoom:67%;" />	

<h3 id="7-3-4-非线性支持向量机"><a href="#7-3-4-非线性支持向量机" class="headerlink" title="7.3.4 非线性支持向量机"></a>7.3.4 非线性支持向量机</h3><p>该部分没啥内容，实际上就是在原有基础上将核函数修改即可，关键就是核函数的选择问题以及理清到底什么样的函数是核函数即可。</p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111212110788.png" alt="image-20241111212110788">	</p>
<h4 id="算法【7-4】-非线性支持向量机"><a href="#算法【7-4】-非线性支持向量机" class="headerlink" title="算法【7.4】 非线性支持向量机"></a>算法【7.4】 非线性支持向量机</h4><p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images%2Fimage-20241111212138151.png" alt="image-20241111212138151">	</p>
<h2 id="7-4-序列最小最优化算法SMO"><a href="#7-4-序列最小最优化算法SMO" class="headerlink" title="7.4 序列最小最优化算法SMO"></a>7.4 序列最小最优化算法SMO</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/433150785">https://zhuanlan.zhihu.com/p/433150785</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://yuezi2048.github.io">yuezi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://yuezi2048.github.io/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/7.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">https://yuezi2048.github.io/2024/12/27/2.Areas🌐/science/Pre/统计学习方法/1.监督学习/7. 支持向量机/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://yuezi2048.github.io" target="_blank">yuezi</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/1-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">1.监督学习</a></div><div class="post-share"><div class="social-share" data-image="/img/touxiang.jpg" data-sites="qq,wechat"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/12/20/2.Areas%F0%9F%8C%90/back-end-java/6.SSM/Spring%20MVC/4.%20%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/" title="4. 常用注解"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">4. 常用注解</div></div><div class="info-2"><div class="info-item-1">四、常用注解 注：本章节的一级目录为demo2  4.1 *@RequestParam 作用： 将请求指定名称的参数给控制器 可以控制该参数是否必须提供，默认值等   属性： value: 请求参数中的名称 required: 请求参数中是否必须提供此参数，默认值为true，表示必须提供，否则会报错。   defaultValue：当前端没有携带该参数时，使用默认值     注：开发中建议加上注解@RequestParam，可以避免因为控制层之后的参数报空指针异常  @Target(&#123;ElementType.PARAMETER&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface RequestParam &#123;    @AliasFor(&quot;name&quot;)    String value() default &quot;&quot;;    @AliasFor(&quot;value&quot;)    String name() default...</div></div></div></a><a class="pagination-related" href="/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/8.%20Boosting/" title="8. Boosting"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">8. Boosting</div></div><div class="info-2"><div class="info-item-1">[TOC] 八、Boosting Boosting在分类问题中，通过改变训练样本的权重，学习多个分类器，将这些分类器进行线性组合，提高分类的性能 本章主要讨论的问题 Boosting思路和代表性AdaBoost算法 探讨为什么能提高学习精度，从前向分布加法模型解释AdaBoost算法 叙述Boosting具体实例——提升树    8.1 AdaBoost算法8.1.1 Boosting基本思路 思想：三个臭皮匠顶过一个诸葛亮的道理，对多个专家的判断进行综合进行判断（提高专家权重，减少普通人的权重） 在概率近似框架（PAC）框架中，一个概念可强学习的充要条件是这个概念可弱学习的，换句话说弱学习算法可以提升（boost）为强学习算法 强可学习：存在一个多项式学习算法能够学习，且正确率高 弱可学习：存在一个多项式学习算法能够学习，但正确率比随机猜测略好   对于分类问题而言，Boosting的思路就是从弱学习算法出发得到一系列弱分类器，再组合这些弱分类器（通常是改变概率分布...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/2.%20%E6%84%9F%E7%9F%A5%E6%9C%BA/" title="2. 感知机"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-27</div><div class="info-item-2">2. 感知机</div></div><div class="info-2"><div class="info-item-1">[TOC] 二、感知机 感知机是二类分类的线性模型，输入为实例的特征向量，输出为实例的类别（取-1和+1） 感知机将实例划分为正负两类的分离超平面，属于判别模型 基于误分类的损失函数，通过梯度下降法对损失函数进行极小化得到感知机模型 感知机包括原始形式和对偶形式，是后续学习神经网络和支持向量机的基础  2.1 感知机模型 感知机模型函数表示如下  	   是一个线性分类模型，属于判别模型 假设空间是定义在特征空间中所有线性分类模型 模型的几何解释如下  	    2.2 感知机学习策略2.2.1 线性可分性 存在一个超平面，完全正确地将正实例点和负实例点划分到超平面的两侧，则称数据集T为线性可分数据集  	    2.2.2 学习策略 我们首先假设训练集线性可分，那么就是要找出这个完全正确划分的超平面，那么学习策略就是要定义经验损失函数并最小化 经验损失函数，并没有天然地选择误分类点的个数来进行判断，因为这不是连续可导，而是选择了所有误分类点到超平面S的总距离进行判断，一个点到平面的距离可以这样表示  	  对于误分类的数据来说，yi和w·xi +...</div></div></div></a><a class="pagination-related" href="/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1.%20%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/" title="1. 统计学习及监督学习概论"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-27</div><div class="info-item-2">1. 统计学习及监督学习概论</div></div><div class="info-2"><div class="info-item-1">[TOC] 一、统计学习及监督学习概论1.1 统计学习 统计学习是计算机系统通过运用数据及统计方法  提高系统性能的机器学习 统计学习研究的对象是数据，提取数据特征，抽象模型，而后回归到数据的分析和预测 基本假设：同类数据具有统计规律性   统计学习的方法包括：监督学习、无监督学习、强化学习 假设数据是独立同分布的，并假设学习的模型属于某个函数的集合（假设空间） 应用某个评价准则，从假设空间中选取最优模型，使他对测试数据在给定的评价准则下由最优的预测，而最优模型的选取由算法实现 因此统计学习方法的三要素：模型、策略、算法   统计学习的步骤 得到有限的训练数据集合 确定包含所有可能的模型假设空间（学习模型的集合） 确定模型选择的准则，即学习的策略 通过学习算法选择最优模型 利用学习的最优模型对新数据进行预测和分析    1.2 统计学习的分类1.2.1...</div></div></div></a><a class="pagination-related" href="/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/3.%20k%E8%BF%91%E9%82%BB%E6%B3%95/" title="3. k近邻法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-27</div><div class="info-item-2">3. k近邻法</div></div><div class="info-2"><div class="info-item-1">[TOC] 三、k近邻法 K-NN是一个基本的分类和回归方法，此处讨论基本的分类问题 输入为实例的特征向量，对应于特征空间的点，输出是实例的类别，可以取多个类 k近邻是假设给定训练数据集，其中的实例类别已定，分类时根据k个最近邻的训练实例类别通过多数表决的方式进行预测，并没有显式的学习过程 k值的选择、距离度量和分类决策规则是k近邻法的3个基本要素  3.1 k近邻算法 特殊的情况是k&#x3D;1时，此时为最近邻算法 k近邻算法没有显式的学习过程  	 3.2 k近邻模型与决策规则3.2.1 模型 k近邻模型主要有3个基本要素：距离度量、k值选择和分类决策规则，确定好上述后，给定一个输入实例，就可以唯一地确定它所属类 在特征空间当中，每一个训练实例点xi，距离该点比其他点更近的所有点组成的一个区域叫做单元(cell)，一个单元构成对于特征空间的一个划分 最近邻算法是实例xi的类yi作为其单元中所有点的类标记(class label)，从而每个单元实例点的类别可以确定，见下图所示    	 3.2.2...</div></div></div></a><a class="pagination-related" href="/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/4.%20%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/" title="4. 朴素贝叶斯法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-27</div><div class="info-item-2">4. 朴素贝叶斯法</div></div><div class="info-2"><div class="info-item-1">[TOC] 四、朴素贝叶斯法 朴素贝叶斯是基于贝叶斯定理和特征条件独立假设的分类方法 对于给定是训练数据集，基于特征条件独立假设学习输入输出的联合概率分布 然后基于该模型对给定的输入x使用贝叶斯定理求出后验概率最大的 输出y  4.1 朴素贝叶斯法的学习与分类4.1.1 模型——基本方法 输入空间X是n维向量集合R^n，输出空间Y是类标记集合{c1, c2, …, ck} 朴素贝叶斯首先学习联合概率分布P(X, Y)，具体需要学习先验概率分布和条件概率分布，这是我们之前提到的生成模型的做法  	  其中，条件概率分布P(X &#x3D; x | Y &#x3D; ck)的参数数量是指数级的，直接估计是不行的  假设n维输入变量，每组x值有Sj组特征，Y可能的取值有k个，根据排列组合，参数的个数就是   因此为了简化问题，朴素贝叶斯作出条件独立性假设，他可以使得X的每组特征是独立的，所以可以直接连乘起来   	 后验概率P(Y = ck | X = x)就可以计算得到如下  其中分母是P(X &#x3D; x)的全概率展开形式，表示y&#x3D;c1, c2, ..,...</div></div></div></a><a class="pagination-related" href="/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/5.%20%E5%86%B3%E7%AD%96%E6%A0%91/" title="5. 决策树"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-27</div><div class="info-item-2">5. 决策树</div></div><div class="info-2"><div class="info-item-1">[TOC] 五、决策树 决策树（decision tree）是一个基本的分类和回归方法，这里主要讨论分类 决策树模型是树型结构，表示基于特征对实例进行分类的过程 被认为是if-then规则的集合（说明了可解释性） 也可以认为是定义在特征空间和类空间上的条件概率分布 有点就是可读性与分类速度快   学习时，在训练数据集上通过损失函数最小化建立决策树模型。预测时，对测试集利用决策树模型进行分类 学习包含三个步骤 特征选择 决策树的生成 决策树的修剪（防止过拟合）   决策树的算法包括：Quinlan在1986年提出的ID3方法，1993年提出的C4.5算法，Breiman等人1986年提出的CART算法  注：这里是后续学习XGBoost和GBDT等高阶决策树模型的基础，所以也需要了解基础模型。 5.1 决策树模型和学习5.1.1...</div></div></div></a><a class="pagination-related" href="/2024/12/27/2.Areas%F0%9F%8C%90/science/Pre/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/1.%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/6.%20%E9%80%BB%E8%BE%91%E6%96%AF%E8%92%82%E5%9B%9E%E5%BD%92%E5%92%8C%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" title="6. 逻辑斯蒂回归和最大熵模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-27</div><div class="info-item-2">6. 逻辑斯蒂回归和最大熵模型</div></div><div class="info-2"><div class="info-item-1">[TOC] 六、logistic回归和最大熵模型 logistic回归是经典分类方法，最大熵模型是概率模型学习中的重要准则，可推广到最大熵模型 maximum entropy model 之所以放在一起说，是因为logistic回归模型和最大熵模型都属于对数线性模型  6.1 logistic回归6.1.1 logistic分布	 我们可根据上述函数绘制出f(x)和F(x)的图形 	 分布函数F(x)属于logistic函数，图形是S形曲线，关于点(u, 1/2)对称s，即满足 	 从F(x)的导数f(x)图像上，我们也可以发现，两端增长速度慢，中心附近增长快 同时可以控制形状变量y，y越小，可以使得中心附近增长的速度越快 6.1.2 二项logistic回归模型二项logistic回归模型是一种分类模型，通过条件概率分布P(Y |...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/loading.gif" data-original="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">yuezi</div><div class="author-info-description">积微者速成</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">785</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">66</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">91</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/yuezi2048"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://githubfast.com/yuezi2048" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/qq_46345703" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="https://qm.qq.com/cgi-bin/qm/qr?k=dD62GIPTf5-iS4UdSfJRy7NHwsrCh3-j" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:joyLing@stumail.nwu.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">积微者速成</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-text">七、支持向量机</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-text">7.1 线性可分支持向量机</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-1-%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86SVM%E6%A8%A1%E5%9E%8B"><span class="toc-text">7.1.1 线性可分SVM模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-2-%E5%87%BD%E6%95%B0%E9%97%B4%E9%9A%94%E4%B8%8E%E5%87%A0%E4%BD%95%E9%97%B4%E9%9A%94"><span class="toc-text">7.1.2 函数间隔与几何间隔</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-3-%E7%A1%AC%E9%97%B4%E9%9A%94%E6%9C%80%E5%A4%A7%E5%8C%96%E7%AD%96%E7%95%A5"><span class="toc-text">7.1.3 硬间隔最大化策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E9%97%B4%E9%9A%94%E5%88%86%E7%A6%BB%E8%B6%85%E5%B9%B3%E9%9D%A2%E5%AD%A6%E4%B9%A0"><span class="toc-text">最大间隔分离超平面学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E3%80%90%E7%AE%97%E6%B3%957-1%E3%80%91-%E6%9C%80%E5%A4%A7%E9%97%B4%E9%9A%94%E6%B3%95%E6%8F%8F%E8%BF%B0"><span class="toc-text">【算法7.1】 最大间隔法描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E9%97%B4%E9%9A%94%E5%88%86%E7%A6%BB%E8%B6%85%E5%B9%B3%E9%9D%A2%E5%AD%98%E5%9C%A8%E5%94%AF%E4%B8%80%E6%80%A7%E8%AF%81%E6%98%8E"><span class="toc-text">最大间隔分离超平面存在唯一性证明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%92%8C%E9%97%B4%E9%9A%94%E8%BE%B9%E7%95%8C"><span class="toc-text">支持向量和间隔边界</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-4-%E5%AF%B9%E5%81%B6%E7%AE%97%E6%B3%95"><span class="toc-text">7.1.4 对偶算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E5%81%B6%E6%B1%82%E8%A7%A3%E8%BF%87%E7%A8%8B"><span class="toc-text">对偶求解过程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E3%80%90%E7%AE%97%E6%B3%957-2%E3%80%91-%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86SVM%E5%AF%B9%E5%81%B6%E7%AE%97%E6%B3%95%E6%8F%8F%E8%BF%B0"><span class="toc-text">【算法7.2】 线性可分SVM对偶算法描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%B8%E4%BC%98%E5%8C%96%E8%A1%A5%E5%85%85%EF%BC%9AKKT-Slater-%E5%AF%B9%E5%81%B6-%E6%B5%81%E7%A8%8B%E6%80%BB%E7%BB%93"><span class="toc-text">*凸优化补充：KKT Slater 对偶 + 流程总结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-text">7.2 线性支持支持向量机</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-1-%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81SVM%E6%A8%A1%E5%9E%8B"><span class="toc-text">7.2.1 线性支持SVM模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-2-%E5%AF%B9%E5%81%B6%E7%AE%97%E6%B3%95"><span class="toc-text">7.2.2 对偶算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E3%80%90%E7%AE%97%E6%B3%957-3%E3%80%91-%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81SVM%E7%AE%97%E6%B3%95%E6%8F%8F%E8%BF%B0"><span class="toc-text">【算法7.3】 线性支持SVM算法描述</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-3-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F"><span class="toc-text">7.2.3 支持向量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-4-%E5%90%88%E9%A1%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-text">7.2.4 合页损失函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E4%B8%8E%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="toc-text">7.3 非线性支持向量机与核函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-1-%E6%A0%B8%E6%8A%80%E5%B7%A7"><span class="toc-text">7.3.1 核技巧</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-text">非线性分类问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89"><span class="toc-text">核函数定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%87%BD%E6%95%B0%E5%9C%A8SVM%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-text">核函数在SVM的应用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-2-%E6%AD%A3%E5%AE%9A%E6%A0%B8"><span class="toc-text">7.3.2 正定核</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E6%98%A0%E5%B0%84"><span class="toc-text">定义映射</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4S"><span class="toc-text">定义内积空间S</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E7%A7%AF%E7%A9%BA%E9%97%B4%E5%AE%8C%E5%A4%87%E5%8C%96%E4%B8%BA%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9%E7%A9%BA%E9%97%B4"><span class="toc-text">内积空间完备化为希尔伯特空间</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA%EF%BC%9A%E6%AD%A3%E5%AE%9A%E6%A0%B8%E5%85%85%E8%A6%81%E6%9D%A1%E4%BB%B6"><span class="toc-text">结论：正定核充要条件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-3-%E5%B8%B8%E7%94%A8%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="toc-text">7.3.3 常用核函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-4-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-text">7.3.4 非线性支持向量机</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E3%80%907-4%E3%80%91-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-text">算法【7.4】 非线性支持向量机</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-4-%E5%BA%8F%E5%88%97%E6%9C%80%E5%B0%8F%E6%9C%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95SMO"><span class="toc-text">7.4 序列最小最优化算法SMO</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/22/Excalidraw/Drawing%202024-11-01%2015.37.37.excalidraw/" title="Drawing 2024-11-01 15.37.37.excalidraw">Drawing 2024-11-01 15.37.37.excalidraw</a><time datetime="2026-02-22T05:56:41.839Z" title="发表于 2026-02-22 13:56:41">2026-02-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/22/2.Areas%F0%9F%8C%90/01.project/condefather/yupao/back-end/7.%E4%BC%98%E5%8C%96%E4%B8%BB%E9%A1%B5%E6%80%A7%E8%83%BD-%E4%BC%98%E5%8C%96%E6%89%B9%E9%87%8F%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE/" title="7.优化主页性能-优化批量导入数据">7.优化主页性能-优化批量导入数据</a><time datetime="2026-02-22T05:56:41.257Z" title="发表于 2026-02-22 13:56:41">2026-02-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/31/2.Areas%F0%9F%8C%90/%E4%B8%B4%E6%97%B6%E8%AE%B0%E5%BD%95/5.%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8/" title="5.工具调用">5.工具调用</a><time datetime="2026-01-31T03:54:22.000Z" title="发表于 2026-01-31 11:54:22">2026-01-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/30/2.Areas%F0%9F%8C%90/%E4%B8%B4%E6%97%B6%E8%AE%B0%E5%BD%95/4.RAG%E8%BF%9B%E9%98%B6/" title="4.RAG进阶">4.RAG进阶</a><time datetime="2026-01-30T13:23:42.000Z" title="发表于 2026-01-30 21:23:42">2026-01-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/27/2.Areas%F0%9F%8C%90/%E4%B8%B4%E6%97%B6%E8%AE%B0%E5%BD%95/3.RAG/" title="3.RAG">3.RAG</a><time datetime="2026-01-27T09:06:56.000Z" title="发表于 2026-01-27 17:06:56">2026-01-27</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/default.png);"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2026 By yuezi</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.0.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/lite/builds/browser.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script></div></div>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body></html>