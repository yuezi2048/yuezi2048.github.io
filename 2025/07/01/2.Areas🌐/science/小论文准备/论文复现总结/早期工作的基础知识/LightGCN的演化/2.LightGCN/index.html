<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>2.LightGCN | yuezi</title><meta name="author" content="yuezi"><meta name="copyright" content="yuezi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="NGCF遵循 GCN 的传播规则，通过特征转换、邻域聚集和非线性激活来细化嵌入，但lightGCN 和NGCF的不同点在于：  lightGCN将GCN中最常见的两种设计：特征转换和非线性激活弃用，因为他们对模型并无实质性作用 另外LightGCN认为自信息的作用不大，也没有使用自信息链接。   LightGCN 核心流程梳理LightGCN 聚焦图协同过滤，核心逻辑是 通过简化的图卷积聚合邻居">
<meta property="og:type" content="article">
<meta property="og:title" content="2.LightGCN">
<meta property="og:url" content="https://yuezi2048.github.io/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/2.LightGCN/index.html">
<meta property="og:site_name" content="yuezi">
<meta property="og:description" content="NGCF遵循 GCN 的传播规则，通过特征转换、邻域聚集和非线性激活来细化嵌入，但lightGCN 和NGCF的不同点在于：  lightGCN将GCN中最常见的两种设计：特征转换和非线性激活弃用，因为他们对模型并无实质性作用 另外LightGCN认为自信息的作用不大，也没有使用自信息链接。   LightGCN 核心流程梳理LightGCN 聚焦图协同过滤，核心逻辑是 通过简化的图卷积聚合邻居">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yuezi2048.github.io/img/touxiang.jpg">
<meta property="article:published_time" content="2025-07-01T03:28:49.000Z">
<meta property="article:modified_time" content="2025-07-01T03:28:49.000Z">
<meta property="article:author" content="yuezi">
<meta property="article:tag" content="LightGCN的演化">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yuezi2048.github.io/img/touxiang.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "2.LightGCN",
  "url": "https://yuezi2048.github.io/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/2.LightGCN/",
  "image": "https://yuezi2048.github.io/img/touxiang.jpg",
  "datePublished": "2025-07-01T03:28:49.000Z",
  "dateModified": "2025-07-01T03:28:49.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "yuezi",
      "url": "https://yuezi2048.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://yuezi2048.github.io/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/2.LightGCN/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?bfb48b678d82bea9f9cc9d59227767e4";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"FPH6F2TOJL","apiKey":"06d9ea26c803ba912b4d8e13404ed34d","indexName":"blog","hitsPerPage":6,"languages":{"input_placeholder":"搜索","hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，耗时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":350,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '2.LightGCN',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/backgound.css"><meta name="generator" content="Hexo 8.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/loading.gif" data-original="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">603</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">61</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">85</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/default.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">yuezi</span></a><a class="nav-page-title" href="/"><span class="site-name">2.LightGCN</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">2.LightGCN</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-01T03:28:49.000Z" title="发表于 2025-07-01 11:28:49">2025-07-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-01T03:28:49.000Z" title="更新于 2025-07-01 11:28:49">2025-07-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/">2.Areas🌐</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/science/">science</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/">小论文准备</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/">论文复现总结</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">早期工作的基础知识</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/2-Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/">LightGCN的演化</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">2.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>11分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><blockquote>
<p>NGCF遵循 GCN 的传播规则，通过特征转换、邻域聚集和非线性激活来细化嵌入，但lightGCN 和NGCF的不同点在于：</p>
<ul>
<li>lightGCN将GCN中最常见的两种设计：特征转换和非线性激活弃用，因为他们对模型并无实质性作用</li>
<li>另外LightGCN认为自信息的作用不大，也没有使用自信息链接。</li>
</ul>
</blockquote>
<h2 id="LightGCN-核心流程梳理"><a href="#LightGCN-核心流程梳理" class="headerlink" title="LightGCN 核心流程梳理"></a>LightGCN 核心流程梳理</h2><p>LightGCN 聚焦图协同过滤，核心逻辑是 <strong>通过简化的图卷积聚合邻居信息，多层传播后加权融合嵌入，最终用于推荐预测</strong>，流程拆解：  </p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images/image-20250630125337530.png" alt="image-20250630125337530">	</p>
<h3 id="图构建"><a href="#图构建" class="headerlink" title="图构建"></a>图构建</h3><blockquote>
<p>将用户 - 物品交互建模为二分图，邻接矩阵 $\mathbf{A} &#x3D; \begin{bmatrix} \mathbf{0} &amp; \mathbf{R} \ \mathbf{R}^\top &amp; \mathbf{0} \end{bmatrix}$（$\mathbf{R}$ 是用户 - 物品交互矩阵 ），度数矩阵 $\mathbf{D}$ 为对角矩阵（元素是节点度数 ）。  </p>
</blockquote>
<p>矩阵表示和NGCF的方式基本相同，其中$\mathbf{D}$是$ (M + N) \times (M + N) $对角矩阵，其中每个条目$D_{ii}$表示邻接矩阵$\mathbf{A}$（也称为度矩阵）的第$i$行向量中非零条目的数量。</p>
<p>$$<br>\mathbf{E}^{(k+1)} &#x3D; \mathbf{D}^{-\frac{1}{2}} \mathbf{A} \mathbf{D}^{-\frac{1}{2}} \mathbf{E}^{(k)}<br>$$</p>
<p>二分图邻接矩阵定义<br>$$<br>\mathbf{A} &#x3D; \begin{pmatrix} \mathbf{0} &amp; \mathbf{R} \ \mathbf{R}^\top &amp; \mathbf{0} \end{pmatrix}<br>$$</p>
<p>图卷积传播后的最终嵌入矩阵（多层加权和）<br>$$<br>\mathbf{E} &#x3D; \alpha_0 \mathbf{E}^{(0)} + \alpha_1 \mathbf{E}^{(1)} + \alpha_2 \mathbf{E}^{(2)} + \dots + \alpha_K \mathbf{E}^{(K)}<br>$$<br>（展开后含幂次形式，体现多层传播累积 ）  </p>
<h3 id="图卷积传播（简化）"><a href="#图卷积传播（简化）" class="headerlink" title="图卷积传播（简化）"></a>图卷积传播（简化）</h3><blockquote>
<p>每层仅做<strong>邻居嵌入聚合</strong>，无特征转换&#x2F;非线性激活，公式（用户侧）：  </p>
</blockquote>
<p> GCN的基本思想是通过平滑图上的特征来学习节点的表示。为此，它迭代执行图卷积，即在自身特征基础上聚合邻居的特征作为目标节点的新表示。这种邻域聚合同样可以抽象为：<br>$$<br>    \mathbf{e}_u^{(k+1)} &#x3D; \text{AGG}\left( \mathbf{e}_u^{(k)}, \left{ \mathbf{e}_i^{(k)} \mid i \in \mathcal{N}_u \right} \right)<br>$$<br>（注：公式中没有再使用自信息链接，作者通过消融实验证明了自信息的多余 ）  </p>
<p><strong>LightGCN 具体传播公式（用户、物品侧）</strong>  </p>
<p>迭代公式如下所示，通过迭代和最后加权求和的方式求取最后对用户和物品的编码并预测（对应矩阵表示）：<br>$$<br>\mathbf{e}<em>u^{(k+1)} &#x3D; \sum</em>{i \in \mathcal{N}_u} \frac{1}{\sqrt{|\mathcal{N}_u|}\sqrt{|\mathcal{N}_i|}} \mathbf{e}_i^{(k)}<br>$$</p>
<p>$$<br>\mathbf{e}<em>i^{(k+1)} &#x3D; \sum</em>{u \in \mathcal{N}_i} \frac{1}{\sqrt{|\mathcal{N}_i|}\sqrt{|\mathcal{N}_u|}} \mathbf{e}_u^{(k)}<br>$$</p>
<p>​		其中， $\mathcal{N}_u$&#x2F;$\mathcal{N}_i$ 是用户&#x2F;物品的邻居集合，$\mathbf{D}$ 是度数矩阵（对角元素为节点度数 ），$\mathbf{E}^{(k)}$ 是第 $k$ 层所有节点（用户 + 物品 ）的嵌入矩阵。  </p>
<h3 id="多层嵌入融合"><a href="#多层嵌入融合" class="headerlink" title="多层嵌入融合"></a><strong>多层嵌入融合</strong></h3><p>在堆叠多层<code>图卷积神经网络</code>时，最后的编码是每一层的编码都会参与，按照权重进行求和的（防止过平滑问题导致所有节点相似），作者提出可以通过注意力机制进行学习该权重，但事实上使用平均权重的效果就会很好，利用注意力机制不一定能取得更好的效果还会加重模型负担。</p>
<p>于是加权公式如下（默认平均加权 $\alpha_k &#x3D; 1&#x2F;(K+1)$ ）：<br>$$<br>\mathbf{e}<em>u &#x3D; \sum</em>{k&#x3D;0}^K \alpha_k \mathbf{e}_u^{(k)}, \quad \mathbf{e}<em>i &#x3D; \sum</em>{k&#x3D;0}^K \alpha_k \mathbf{e}_i^{(k)}<br>$$</p>
<h3 id="预测得分（内积）"><a href="#预测得分（内积）" class="headerlink" title="预测得分（内积）"></a>预测得分（内积）</h3><p>​    预测部分和NGCF方式基本一样，直接将用户的最终编码（通过邻居聚合传递）和物品表示（通过图传播）的最终编码相乘得到用户评分矩阵类似的排序。<br>$$<br>\hat{y}_{ui} &#x3D; \mathbf{e}_u^{<em>\top} \mathbf{e}_i^</em><br>$$<br>（注：原文简写为 $\hat{y}_{ui} \approx \mathbf{e}_u^{<em>\top} \mathbf{e}_i^</em>$ ，表示与评分排序逻辑一致 ）  </p>
<p>最终是基于BPR loss对排序方法进行了改进，改进模型的收敛速度和效果。<br>$$<br>L_{\text{BPR}} &#x3D; -\sum_{u&#x3D;1}^{M} \sum_{i \in \mathcal{N}<em>u} \sum</em>{j \notin \mathcal{N}<em>u} \ln \sigma(\hat{y}</em>{ui} - \hat{y}_{uj}) + \lambda ||\mathbf{E}^{(0)}||^2<br>$$<br>BPR损失参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_46006468/article/details/125987744">https://blog.csdn.net/qq_46006468/article/details/125987744</a></p>
<h2 id="实验效果"><a href="#实验效果" class="headerlink" title="实验效果"></a>实验效果</h2><p> LightGCN通过消融实验证明了非线性激活和特征转换这些GCN的结构在推荐系统中并不适用，这很可能是因为推荐系统中每个图节点仅仅使用了用户或者物品的ID进行模型搭建和训练，因此节点信息并不像图片信息那么丰富，也就不需要那么复杂的结构了。消融实验结果如图 </p>
<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images/b7a3dfff1cdad2ec9e60e5a86ef78277.png" alt="img">	</p>
<p>•NGCF-f，删除特征转换矩阵W1和W2。</p>
<p>•NGCF-n，去除非线性激活函数σ。</p>
<p>•NGCF fn，去除特征转换矩阵和非线性激活函数。</p>
<p>结果显示NGCF fn的结果要比NGCF的结果更加优秀，提升16%，可以认为该两种结构确实不是必须的。</p>
<h2 id="代码复现"><a href="#代码复现" class="headerlink" title="代码复现"></a>代码复现</h2><h3 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h3><blockquote>
<p>keep_prob：drop_out保留比例</p>
<p>权重初始化作者采用了normal初始化而不是Xavier初始化（前向传播时每一层输出的方差相等）</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, </span></span><br><span class="line"><span class="params">                 config:<span class="built_in">dict</span>, </span></span><br><span class="line"><span class="params">                 dataset:BasicDataset</span>):</span><br><span class="line">        <span class="built_in">super</span>(LightGCN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.config = config</span><br><span class="line">        <span class="variable language_">self</span>.dataset : dataloader.BasicDataset = dataset</span><br><span class="line">        <span class="variable language_">self</span>.__init_weight()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init_weight</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.num_users  = <span class="variable language_">self</span>.dataset.n_users</span><br><span class="line">        <span class="variable language_">self</span>.num_items  = <span class="variable language_">self</span>.dataset.m_items</span><br><span class="line">        <span class="variable language_">self</span>.latent_dim = <span class="variable language_">self</span>.config[<span class="string">&#x27;latent_dim_rec&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.n_layers = <span class="variable language_">self</span>.config[<span class="string">&#x27;lightGCN_n_layers&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.keep_prob = <span class="variable language_">self</span>.config[<span class="string">&#x27;keep_prob&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.A_split = <span class="variable language_">self</span>.config[<span class="string">&#x27;A_split&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.embedding_user = torch.nn.Embedding(</span><br><span class="line">            num_embeddings=<span class="variable language_">self</span>.num_users, embedding_dim=<span class="variable language_">self</span>.latent_dim)</span><br><span class="line">        <span class="variable language_">self</span>.embedding_item = torch.nn.Embedding(</span><br><span class="line">            num_embeddings=<span class="variable language_">self</span>.num_items, embedding_dim=<span class="variable language_">self</span>.latent_dim)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.config[<span class="string">&#x27;pretrain&#x27;</span>] == <span class="number">0</span>:</span><br><span class="line"><span class="comment">#             nn.init.xavier_uniform_(self.embedding_user.weight, gain=1)</span></span><br><span class="line"><span class="comment">#             nn.init.xavier_uniform_(self.embedding_item.weight, gain=1)</span></span><br><span class="line"><span class="comment">#             print(&#x27;use xavier initilizer&#x27;)</span></span><br><span class="line"><span class="comment"># random normal init seems to be a better choice when lightGCN actually don&#x27;t use any non-linear activation function</span></span><br><span class="line">            nn.init.normal_(<span class="variable language_">self</span>.embedding_user.weight, std=<span class="number">0.1</span>)</span><br><span class="line">            nn.init.normal_(<span class="variable language_">self</span>.embedding_item.weight, std=<span class="number">0.1</span>)</span><br><span class="line">            world.cprint(<span class="string">&#x27;use NORMAL distribution initilizer&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.embedding_user.weight.data.copy_(torch.from_numpy(<span class="variable language_">self</span>.config[<span class="string">&#x27;user_emb&#x27;</span>]))</span><br><span class="line">            <span class="variable language_">self</span>.embedding_item.weight.data.copy_(torch.from_numpy(<span class="variable language_">self</span>.config[<span class="string">&#x27;item_emb&#x27;</span>]))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;use pretarined data&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.f = nn.Sigmoid()</span><br><span class="line">        <span class="variable language_">self</span>.Graph = <span class="variable language_">self</span>.dataset.getSparseGraph()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;lgn is already to go(dropout:<span class="subst">&#123;self.config[<span class="string">&#x27;dropout&#x27;</span>]&#125;</span>)&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h3><blockquote>
<p>如果是训练集并且配置项中配置了dropout，才需要dropout</p>
<p>真正传播的过程：</p>
<ul>
<li>多层传播：通过for layer in range(self.n_layers)循环进行多层图卷积；</li>
<li>邻居信息聚合：使用邻接矩阵g_droped与节点嵌入all_emb相乘，聚合邻居信息；</li>
<li>处理子图分裂情况：若启用A_split，则分别在每个子图上计算后再拼接；</li>
<li>嵌入集成：将每一层的嵌入结果存入embs，最后取均值得到最终节点表示；（stack操作）</li>
<li>输出用户和物品嵌入：将输出分割为用户和物品两部分并返回。（split操作）</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, users, items</span>):</span><br><span class="line">    <span class="comment"># compute embedding</span></span><br><span class="line">    all_users, all_items = <span class="variable language_">self</span>.computer()</span><br><span class="line">    <span class="comment"># print(&#x27;forward&#x27;)</span></span><br><span class="line">    <span class="comment">#all_users, all_items = self.computer()</span></span><br><span class="line">    users_emb = all_users[users]</span><br><span class="line">    items_emb = all_items[items]</span><br><span class="line">    inner_pro = torch.mul(users_emb, items_emb) <span class="comment"># 内积</span></span><br><span class="line">    gamma     = torch.<span class="built_in">sum</span>(inner_pro, dim=<span class="number">1</span>) <span class="comment"># 点积</span></span><br><span class="line">    <span class="keyword">return</span> gamma</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getEmbedding</span>(<span class="params">self, users, pos_items, neg_items</span>):</span><br><span class="line">    all_users, all_items = <span class="variable language_">self</span>.computer()</span><br><span class="line">    users_emb = all_users[users]</span><br><span class="line">    pos_emb = all_items[pos_items]</span><br><span class="line">    neg_emb = all_items[neg_items]</span><br><span class="line">    users_emb_ego = <span class="variable language_">self</span>.embedding_user(users)</span><br><span class="line">    pos_emb_ego = <span class="variable language_">self</span>.embedding_item(pos_items)</span><br><span class="line">    neg_emb_ego = <span class="variable language_">self</span>.embedding_item(neg_items)</span><br><span class="line">    <span class="keyword">return</span> users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computer</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    propagate methods for lightGCN</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>       </span><br><span class="line">    users_emb = <span class="variable language_">self</span>.embedding_user.weight</span><br><span class="line">    items_emb = <span class="variable language_">self</span>.embedding_item.weight</span><br><span class="line">    all_emb = torch.cat([users_emb, items_emb])</span><br><span class="line">    <span class="comment">#   torch.split(all_emb , [self.num_users, self.num_items])</span></span><br><span class="line">    embs = [all_emb]</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.config[<span class="string">&#x27;dropout&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.training:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;droping&quot;</span>)</span><br><span class="line">            g_droped = <span class="variable language_">self</span>.__dropout(<span class="variable language_">self</span>.keep_prob)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            g_droped = <span class="variable language_">self</span>.Graph        </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        g_droped = <span class="variable language_">self</span>.Graph    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.n_layers):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.A_split:</span><br><span class="line">            temp_emb = []</span><br><span class="line">            <span class="keyword">for</span> f <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(g_droped)):</span><br><span class="line">                temp_emb.append(torch.sparse.mm(g_droped[f], all_emb))</span><br><span class="line">            side_emb = torch.cat(temp_emb, dim=<span class="number">0</span>)</span><br><span class="line">            all_emb = side_emb</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            all_emb = torch.sparse.mm(g_droped, all_emb)</span><br><span class="line">        embs.append(all_emb)</span><br><span class="line">    embs = torch.stack(embs, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#print(embs.size())</span></span><br><span class="line">    light_out = torch.mean(embs, dim=<span class="number">1</span>)</span><br><span class="line">    users, items = torch.split(light_out, [<span class="variable language_">self</span>.num_users, <span class="variable language_">self</span>.num_items])</span><br><span class="line">    <span class="keyword">return</span> users, items</span><br></pre></td></tr></table></figure>

<h4 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h4><blockquote>
<p>涉及到拆分图的概念（A_split参数）：划分为多个子图进行Dropout，对应的就是对整个图进行dropout</p>
<p>这里的dropout_x操作就是生成随机掩码random_index来进行归一化地保留某县边</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__dropout</span>(<span class="params">self, keep_prob</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.A_split:</span><br><span class="line">        graph = []</span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> <span class="variable language_">self</span>.Graph:</span><br><span class="line">            graph.append(<span class="variable language_">self</span>.__dropout_x(g, keep_prob))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        graph = <span class="variable language_">self</span>.__dropout_x(<span class="variable language_">self</span>.Graph, keep_prob)</span><br><span class="line">    <span class="keyword">return</span> graph</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__dropout_x</span>(<span class="params">self, x, keep_prob</span>):</span><br><span class="line">    size = x.size()</span><br><span class="line">    index = x.indices().t()</span><br><span class="line">    values = x.values()</span><br><span class="line">    random_index = torch.rand(<span class="built_in">len</span>(values)) + keep_prob</span><br><span class="line">    random_index = random_index.<span class="built_in">int</span>().<span class="built_in">bool</span>()</span><br><span class="line">    index = index[random_index]</span><br><span class="line">    values = values[random_index]/keep_prob</span><br><span class="line">    g = torch.sparse.FloatTensor(index.t(), values, size)</span><br><span class="line">    <span class="keyword">return</span> g</span><br></pre></td></tr></table></figure>

<h3 id="后向传播"><a href="#后向传播" class="headerlink" title="后向传播"></a>后向传播</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(world.TRAIN_epochs):</span><br><span class="line">        start = time.time()</span><br><span class="line">        <span class="keyword">if</span> epoch %<span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            cprint(<span class="string">&quot;[TEST]&quot;</span>)</span><br><span class="line">            Procedure.Test(dataset, Recmodel, epoch, w, world.config[<span class="string">&#x27;multicore&#x27;</span>])</span><br><span class="line">        output_information = Procedure.BPR_train_original(dataset, Recmodel, bpr, epoch, neg_k=Neg_k,w=w)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;EPOCH[<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;world.TRAIN_epochs&#125;</span>] <span class="subst">&#123;output_information&#125;</span>&#x27;</span>)</span><br><span class="line">        torch.save(Recmodel.state_dict(), weight_file)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">BPR_train_original</span>(<span class="params">dataset, recommend_model, loss_class, epoch, neg_k=<span class="number">1</span>, w=<span class="literal">None</span></span>):</span><br><span class="line">    Recmodel = recommend_model</span><br><span class="line">    Recmodel.train()</span><br><span class="line">    bpr: utils.BPRLoss = loss_class</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> timer(name=<span class="string">&quot;Sample&quot;</span>):</span><br><span class="line">        S = utils.UniformSample_original(dataset)</span><br><span class="line">    users = torch.Tensor(S[:, <span class="number">0</span>]).long()</span><br><span class="line">    posItems = torch.Tensor(S[:, <span class="number">1</span>]).long()</span><br><span class="line">    negItems = torch.Tensor(S[:, <span class="number">2</span>]).long()</span><br><span class="line"></span><br><span class="line">    users = users.to(world.device)</span><br><span class="line">    posItems = posItems.to(world.device)</span><br><span class="line">    negItems = negItems.to(world.device)</span><br><span class="line">    users, posItems, negItems = utils.shuffle(users, posItems, negItems)</span><br><span class="line">    total_batch = <span class="built_in">len</span>(users) // world.config[<span class="string">&#x27;bpr_batch_size&#x27;</span>] + <span class="number">1</span></span><br><span class="line">    aver_loss = <span class="number">0.</span></span><br><span class="line">    <span class="keyword">for</span> (batch_i,</span><br><span class="line">         (batch_users,</span><br><span class="line">          batch_pos,</span><br><span class="line">          batch_neg)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(utils.minibatch(users,</span><br><span class="line">                                                   posItems,</span><br><span class="line">                                                   negItems,</span><br><span class="line">                                                   batch_size=world.config[<span class="string">&#x27;bpr_batch_size&#x27;</span>])):</span><br><span class="line">        cri = bpr.stageOne(batch_users, batch_pos, batch_neg)</span><br><span class="line">        aver_loss += cri</span><br><span class="line">        <span class="keyword">if</span> world.tensorboard:</span><br><span class="line">            w.add_scalar(<span class="string">f&#x27;BPRLoss/BPR&#x27;</span>, cri, epoch * <span class="built_in">int</span>(<span class="built_in">len</span>(users) / world.config[<span class="string">&#x27;bpr_batch_size&#x27;</span>]) + batch_i)</span><br><span class="line">    aver_loss = aver_loss / total_batch</span><br><span class="line">    time_info = timer.<span class="built_in">dict</span>()</span><br><span class="line">    timer.zero()</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;loss<span class="subst">&#123;aver_loss:<span class="number">.3</span>f&#125;</span>-<span class="subst">&#123;time_info&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stageOne</span>(<span class="params">self, users, pos, neg</span>):</span><br><span class="line">    loss, reg_loss = <span class="variable language_">self</span>.model.bpr_loss(users, pos, neg)</span><br><span class="line">    reg_loss = reg_loss*<span class="variable language_">self</span>.weight_decay</span><br><span class="line">    loss = loss + reg_loss</span><br><span class="line"></span><br><span class="line">    <span class="variable language_">self</span>.opt.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="variable language_">self</span>.opt.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss.cpu().item()</span><br></pre></td></tr></table></figure>



<h3 id="tensorboard可视化"><a href="#tensorboard可视化" class="headerlink" title="tensorboard可视化"></a>tensorboard可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># init tensorboard</span></span><br><span class="line"><span class="keyword">if</span> world.tensorboard:</span><br><span class="line">    w : SummaryWriter = SummaryWriter(</span><br><span class="line">                                    join(world.BOARD_PATH, time.strftime(<span class="string">&quot;%m-%d-%Hh%Mm%Ss-&quot;</span>) + <span class="string">&quot;-&quot;</span> + world.comment)</span><br><span class="line">                                    )</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    w = <span class="literal">None</span></span><br><span class="line">    world.cprint(<span class="string">&quot;not enable tensorflowboard&quot;</span>)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<p>训练：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> world.tensorboard:</span><br><span class="line">            w.add_scalar(<span class="string">f&#x27;BPRLoss/BPR&#x27;</span>, cri, epoch * <span class="built_in">int</span>(<span class="built_in">len</span>(users) / world.config[<span class="string">&#x27;bpr_batch_size&#x27;</span>]) + batch_i)</span><br></pre></td></tr></table></figure>

<p>结果展示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir=<span class="string">&quot;/path/to/log-directory&quot;</span></span><br></pre></td></tr></table></figure>

<p>AutoDL：<a target="_blank" rel="noopener" href="https://www.autodl.com/docs/tensorboard/">https://www.autodl.com/docs/tensorboard/</a></p>
<p>tensorboard的event文件默认保存到&#x2F;root&#x2F;tf-logs&#x2F;路径，手动添加的方式</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tensorboard --port 6007 --logdir /path/to/your/tf-logs/direction</span><br></pre></td></tr></table></figure>

<p><img src="/img/loading.gif" data-original="https://yuezi-1308313119.cos.ap-guangzhou.myqcloud.com/typora-user-images/image-20250630162726679.png" alt="image-20250630162726679">	</p>
<h2 id="论文连接"><a href="#论文连接" class="headerlink" title="论文连接"></a>论文连接</h2><ul>
<li>LightGCN： <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2002.02126">https://arxiv.org/abs/2002.02126</a></li>
<li>BPR： <a target="_blank" rel="noopener" href="https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf">https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf</a></li>
</ul>
<p>refer：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_46006468/article/details/126060701">https://blog.csdn.net/qq_46006468/article/details/126060701</a></li>
<li>github:<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/gusye1234/LightGCN-PyTorch">https://github.com/gusye1234/LightGCN-PyTorch</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kuandeng/LightGCN">https://github.com/kuandeng/LightGCN</a></li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://yuezi2048.github.io">yuezi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://yuezi2048.github.io/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/2.LightGCN/">https://yuezi2048.github.io/2025/07/01/2.Areas🌐/science/小论文准备/论文复现总结/早期工作的基础知识/LightGCN的演化/2.LightGCN/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://yuezi2048.github.io" target="_blank">yuezi</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/">LightGCN的演化</a></div><div class="post-share"><div class="social-share" data-image="/img/touxiang.jpg" data-sites="qq,wechat"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E6%9C%AC%E5%8A%9F/%E5%90%84%E4%B8%AA%E7%89%88%E6%9C%AC%E7%9A%84%E4%B9%98%E6%B3%95/" title="各个版本的乘法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">各个版本的乘法</div></div><div class="info-2"><div class="info-item-1">torch.sparse.mm(a, b)是对torch.mm的特殊情况下的优化。 torch.sparse.mm(a, b)场景：  GNN中邻接矩阵与嵌入相乘  all_emb = torch.sparse.mm(g_droped, all_emb)  torch.mul是逐位相乘：  如计算BPR损失中的正向分数  pos_scores = torch.mul(users_emb, pos_emb)pos_scores = torch.sum(pos_scores, dim=1)  torch.matmul场景  如计算用户评分时，需要计算内积来评估相似度  rating = self.f(torch.matmul(users_emb, items_emb.t()))         操作名称 作用描述 典型使用场景 数学意义 输入类型要求    torch.sparse.mm(a, b) 稀疏矩阵与稠密矩阵相乘 图传播（邻居信息聚合） 邻接矩阵 × 嵌入矩阵 a 是稀疏张量，b 是稠密张量满足 (m, k) × (k, n)   torch.mul(a,...</div></div></div></a><a class="pagination-related" href="/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/3.SGL/" title="3.SGL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">3.SGL</div></div><div class="info-2"><div class="info-item-1"> 从 LightGCN 到 SGL：基于对比学习的图推荐系统逐渐受到关注，SGL 是其中的代表方法3。SGL 以 LightGCN 为基础，采用基于抽样、dropout 等方式的图数据增强策略来构造用户 - 物品交互图的不同视角，以此提供额外监督信号，并使用 InfoNCE loss+BPR loss+Reg Loss 三个损失函数，在收敛速度、推荐性能和鲁棒性等方面展现出优势13。  背景利用图卷积神经网络处理推荐系统的问题任然有很大局限性，即使是LightGCN也存在的问题，局限性主要在于：  高度节点对表征学习的影响更大，低度(长尾)节点的推荐效果更差; 表示容易受到噪声交互的影响，因为邻域聚合方案进一步扩大了观察到的边的影响。 目前大多数推荐学习任务都是基于监督学习的范式，其中监督信号一般指用户和物品的交互数据。然而这些交互数据通常来说是异常稀疏的，不足以学习高质量的表征。  而自监督对比学习可以有效解决标记数据不足的网络训练困难、不准确的问题。因此，将自监督学习（Self-supervised Learning,...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/1.NGCF/" title="1.NGCF"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-01</div><div class="info-item-2">1.NGCF</div></div><div class="info-2"><div class="info-item-1">NGCF 传统协同过滤（如基于矩阵分解的方法）仅利用用户 - 物品交互的全局统计信息，缺乏对高阶关联的挖掘。NCF（神经协同过滤） 首次将神经网络引入协同过滤，用多层感知机（MLP）学习用户、物品嵌入的非线性交互，突破了矩阵分解的线性限制，但未显式利用图结构信息 随着图神经网络（GNN）兴起，用户 - 物品交互可建模为二分图（用户、物品为节点，交互为边 ）。NGCF（神经图协同过滤） 在此背景下诞生，核心改进是：  引入图结构：将用户 - 物品交互视为图，通过图卷积（GCN 变体）传播邻居信息，让嵌入学习能捕获用户 - 物品的高阶关联（如用户 A 喜欢物品 X，物品 X 被用户 B 喜欢，NGCF 可传递这种间接关联 ）。 消息传递机制：定义从物品到用户（或反之）的消息构造公式（如 $\mathbf{m}_{u \leftarrow i} &#x3D; \frac{1}{\sqrt{|\mathcal{N}_u||\mathcal{N}_i|}} \left( \mathbf{W}_1 \mathbf{e}_i + \mathbf{W}_2 (\mathbf{e}_i...</div></div></div></a><a class="pagination-related" href="/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/4.SimGCL/" title="4.SimGCL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-01</div><div class="info-item-2">4.SimGCL</div></div><div class="info-2"><div class="info-item-1">  从 SGL 到 SimGCL：SimGCL 是在 SGL 和 LightGCN 基础上的进一步改进。它发现 SGL 中图增强操作对实验效果作用不大，反而增加了计算量和复杂度，因此 SimGCL 没有使用 SGL 的图增强算法，而是保留了其损失函数，同时沿用 LightGCN 的图计算传播、参数训练等模块。为提高嵌入的均匀性、增强模型鲁棒性和泛化能力，SimGCL 针对每一层图卷积最后的嵌入都加入了噪声，实验证明该方法能有效提升推荐能力。  此外，后续还有一些基于这些模型的改进版本，如 XSimGCL 将对比任务和主推荐任务融为一体，采用跨层对比来计算对比损失，进一步降低了时间开销  还有 LAGCL（长尾增强的图对比学习方法），针对现有方法未考虑头部与尾部节点差异的问题，通过长尾增强技术使模型产出更均匀更准确的节点表征，以改进基于 GNN 的推荐任务。    SGL的价值在于损失函数在对比学习图卷积推荐算法SGL中，使用了三种方法进行图增强，包括随机去除一些点和对应的边（ND），随机取出一些边（ED），还有每一层layer都随机去除一些点和边（RW），如下图所示：  	 ​...</div></div></div></a><a class="pagination-related" href="/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/3.SGL/" title="3.SGL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-01</div><div class="info-item-2">3.SGL</div></div><div class="info-2"><div class="info-item-1"> 从 LightGCN 到 SGL：基于对比学习的图推荐系统逐渐受到关注，SGL 是其中的代表方法3。SGL 以 LightGCN 为基础，采用基于抽样、dropout 等方式的图数据增强策略来构造用户 - 物品交互图的不同视角，以此提供额外监督信号，并使用 InfoNCE loss+BPR loss+Reg Loss 三个损失函数，在收敛速度、推荐性能和鲁棒性等方面展现出优势13。  背景利用图卷积神经网络处理推荐系统的问题任然有很大局限性，即使是LightGCN也存在的问题，局限性主要在于：  高度节点对表征学习的影响更大，低度(长尾)节点的推荐效果更差; 表示容易受到噪声交互的影响，因为邻域聚合方案进一步扩大了观察到的边的影响。 目前大多数推荐学习任务都是基于监督学习的范式，其中监督信号一般指用户和物品的交互数据。然而这些交互数据通常来说是异常稀疏的，不足以学习高质量的表征。  而自监督对比学习可以有效解决标记数据不足的网络训练困难、不准确的问题。因此，将自监督学习（Self-supervised Learning,...</div></div></div></a><a class="pagination-related" href="/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/5.1%20HyperGCN/" title="5.1 HyperGCN"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-01</div><div class="info-item-2">5.1 HyperGCN</div></div><div class="info-2"><div class="info-item-1">  图神经网络在各个研究领域引起了广泛的关注并取得了显著的成绩。大多数算法都假设图中节点是成对出现的，即一条边只能连接两个节点。然而，在许多实际应用中，对象之间的关系是高阶的，超出了成对关系，可能会导致数据分布不平衡、无法准确描述对象之间的关系等问题。 超图（Hypergraph）提供了一种灵活而自然的建模工具来对这种复杂的关系进行建模。在许多真实的网络中，这种复杂关系普遍存在，因此激发了使用超图学习的问题。一种流行的学习方法是基于超图的半监督学习(SSL)，其目标是对超图中未标记的顶点分配标签。 在推荐系统的图神经网络之中，对比学习SSL和图卷积算法受的启发，提出了HyperGCN，即超图卷积神经网络，这是一种基于超图的谱论来训练用于超图上半监督学习的GCN的新方法。  超图超图的边（超边...</div></div></div></a><a class="pagination-related" href="/2025/07/01/2.Areas%F0%9F%8C%90/science/%E5%B0%8F%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%80%BB%E7%BB%93/%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/LightGCN%E7%9A%84%E6%BC%94%E5%8C%96/5.GDE/" title="5.GDE"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-01</div><div class="info-item-2">5.GDE</div></div><div class="info-2"><div class="info-item-1"> 前人的工作中，对图卷积中的领域聚合研究的不够透彻，所以作者在频域下对图卷积进行分析。分析得到两个结论： a.只有少部分的邻居的平滑或者差异信息对推荐有促进，大部分的图信息都可以看作噪声； b.反复的图卷积操作只能促进邻居平滑，不能有效过滤噪声，并且低效。并且基于此进一步提出了一个高效的GCN（超图卷积），作为带通滤波器，此外动态调整negative sample的梯度加快收敛。  想法...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/loading.gif" data-original="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">yuezi</div><div class="author-info-description">积微者速成</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">603</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">61</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">85</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/yuezi2048"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://githubfast.com/yuezi2048" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/qq_46345703" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="https://qm.qq.com/cgi-bin/qm/qr?k=dD62GIPTf5-iS4UdSfJRy7NHwsrCh3-j" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:joyLing@stumail.nwu.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">积微者速成</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#LightGCN-%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B%E6%A2%B3%E7%90%86"><span class="toc-text">LightGCN 核心流程梳理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%BE%E6%9E%84%E5%BB%BA"><span class="toc-text">图构建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%BE%E5%8D%B7%E7%A7%AF%E4%BC%A0%E6%92%AD%EF%BC%88%E7%AE%80%E5%8C%96%EF%BC%89"><span class="toc-text">图卷积传播（简化）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%B1%82%E5%B5%8C%E5%85%A5%E8%9E%8D%E5%90%88"><span class="toc-text">多层嵌入融合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E5%BE%97%E5%88%86%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89"><span class="toc-text">预测得分（内积）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E6%95%88%E6%9E%9C"><span class="toc-text">实验效果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0"><span class="toc-text">代码复现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-text">参数初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-text">前向传播</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#dropout"><span class="toc-text">dropout</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8E%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-text">后向传播</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tensorboard%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-text">tensorboard可视化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E8%BF%9E%E6%8E%A5"><span class="toc-text">论文连接</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/31/Excalidraw/Drawing%202024-11-01%2015.37.37.excalidraw/" title="Drawing 2024-11-01 15.37.37.excalidraw">Drawing 2024-11-01 15.37.37.excalidraw</a><time datetime="2025-10-31T04:19:26.621Z" title="发表于 2025-10-31 12:19:26">2025-10-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/31/2.Areas%F0%9F%8C%90/01.project/condefather/yupao/back-end/7.%E4%BC%98%E5%8C%96%E4%B8%BB%E9%A1%B5%E6%80%A7%E8%83%BD-%E4%BC%98%E5%8C%96%E6%89%B9%E9%87%8F%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE/" title="7.优化主页性能-优化批量导入数据">7.优化主页性能-优化批量导入数据</a><time datetime="2025-10-31T04:19:26.102Z" title="发表于 2025-10-31 12:19:26">2025-10-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/31/2.Areas%F0%9F%8C%90/02.%E9%9D%A2%E7%BB%8F%E8%AE%B0%E5%BD%95/MySQL/81.%E4%BB%80%E4%B9%88%E6%98%AF%E6%B8%B8%E6%A0%87Cursor%E5%88%86%E9%A1%B5_%E5%AF%B9%E6%AF%94%E4%BC%A0%E7%BB%9FLIMIT_OFFSET%E5%88%86%E9%A1%B5%E7%9A%84%E4%BC%98%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88/" title="81.什么是游标Cursor分页_对比传统LIMIT_OFFSET分页的优势是什么">81.什么是游标Cursor分页_对比传统LIMIT_OFFSET分页的优势是什么</a><time datetime="2025-10-31T04:14:27.000Z" title="发表于 2025-10-31 12:14:27">2025-10-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/31/2.Areas%F0%9F%8C%90/02.%E9%9D%A2%E7%BB%8F%E8%AE%B0%E5%BD%95/MySQL/80.%E5%85%A8%E9%87%8F%E5%90%8C%E6%AD%A5%E5%92%8C%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5%E5%90%84%E8%87%AA%E4%BC%98%E7%BC%BA%E7%82%B9/" title="80.全量同步和增量同步各自优缺点">80.全量同步和增量同步各自优缺点</a><time datetime="2025-10-31T04:13:32.000Z" title="发表于 2025-10-31 12:13:32">2025-10-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/31/2.Areas%F0%9F%8C%90/02.%E9%9D%A2%E7%BB%8F%E8%AE%B0%E5%BD%95/MySQL/79.%E4%BB%80%E4%B9%88%E6%98%AF%E6%89%B9%E9%87%8F%E6%95%B0%E6%8D%AE%E5%85%A5%E5%BA%93_%E7%9B%B8%E6%AF%94%E5%8D%95%E6%9D%A1%E6%8F%92%E5%85%A5%E4%BC%98%E5%8A%BF/" title="79.什么是批量数据入库_相比单条插入优势">79.什么是批量数据入库_相比单条插入优势</a><time datetime="2025-10-31T04:03:26.000Z" title="发表于 2025-10-31 12:03:26">2025-10-31</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/default.png);"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By yuezi</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.0.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/lite/builds/browser.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script></div></div>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body></html>